{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Politikbereich</th>\n",
       "      <th>Zweck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Verkehr</td>\n",
       "      <td>Nord-Süd-Tangente; Linie 26/27, 2.2. Teil-BPU,A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bildung</td>\n",
       "      <td>Gedenken zu 30 Jahre Mauerfall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stadtentwicklung</td>\n",
       "      <td>Lernen Na Logo - Bildungsnetzwerk Hellersdorfer Promenade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jugend</td>\n",
       "      <td>Kinder- und Jugendambulanz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jugend</td>\n",
       "      <td>Therapiebad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Politikbereich                                                      Zweck\n",
       "0           Verkehr            Nord-Süd-Tangente; Linie 26/27, 2.2. Teil-BPU,A\n",
       "1           Bildung                             Gedenken zu 30 Jahre Mauerfall\n",
       "2  Stadtentwicklung  Lernen Na Logo - Bildungsnetzwerk Hellersdorfer Promenade\n",
       "3            Jugend                                 Kinder- und Jugendambulanz\n",
       "4            Jugend                                                Therapiebad"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/augmented_data.csv\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.loc[:, df.columns != 'Politikbereich'], df.loc[:,df.columns == 'Politikbereich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21,  2, 18, ..., 20, 20, 20])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(y[\"Politikbereich\"].unique().tolist())\n",
    "y = y[\"Politikbereich\"].apply(lambda s: le.transform([s])[0]).values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5230</th>\n",
       "      <th>5231</th>\n",
       "      <th>5232</th>\n",
       "      <th>5233</th>\n",
       "      <th>5234</th>\n",
       "      <th>5235</th>\n",
       "      <th>5236</th>\n",
       "      <th>5237</th>\n",
       "      <th>5238</th>\n",
       "      <th>5239</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  5230  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   5231  5232  5233  5234  5235  5236  5237  5238  5239  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[3 rows x 5240 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from lib.bert_pytorch.helper_functions import get_device\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "class SelectFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_list):\n",
    "        self.features_list = features_list\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X[self.features_list]\n",
    "        X = X.iloc[:,0]\n",
    "        return X\n",
    "\n",
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def cleaner(self, text):\n",
    "        # Remove mid slash and digits\n",
    "        text = re.sub(r'-', ' ', text)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        # Custom ones not supported by spacy\n",
    "        text = re.sub(r'Abs\\.', 'Absatz', text)\n",
    "        text = re.sub(r'e\\.V\\.', 'eingetragener Verein', text)\n",
    "        text = re.sub(r'co\\.', 'Kompanie', text)\n",
    "        text = re.sub(r'Co\\.', 'Kompanie', text)\n",
    "        text = re.sub(r'gem\\.', 'gemäß', text)\n",
    "        text = re.sub(r\"'s\", '', text)\n",
    "        return text\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.apply(self.cleaner)\n",
    "        return X\n",
    "\n",
    "class SpacyLemmatizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"de_core_news_lg\")\n",
    "        self.nlp.remove_pipe(\"ner\")\n",
    "        self.nlp.remove_pipe(\"parser\")\n",
    "        self.nlp.remove_pipe(\"attribute_ruler\")\n",
    "    def normalize(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        output = []\n",
    "        for token in doc:\n",
    "            if not token.is_punct and not token.is_stop and not token.is_space:\n",
    "                output.append(token.lemma_)\n",
    "        return \" \".join(output)\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.apply(self.normalize)\n",
    "        return X\n",
    "\n",
    "class Lowercase(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.apply(lambda text: text.lower())\n",
    "        return X\n",
    "\n",
    "class TfIdfVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        tfidf_encodings = self.vectorizer.transform(X)\n",
    "        X = pd.DataFrame(tfidf_encodings.toarray())\n",
    "        return X\n",
    "\n",
    "class BertSentenceEmbeddigs(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "        self.device = get_device()\n",
    "        self.model = BertModel.from_pretrained('bert-base-german-cased', \n",
    "                                                output_hidden_states=True)\\\n",
    "                                                    .to(self.device)\n",
    "        self.model.eval()\n",
    "    def embed_sentence(self, sentence: str):\n",
    "        ids_tensor = self.tokenizer.encode(sentence, return_tensors='pt')\n",
    "        ids_tensor = ids_tensor.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            out = self.model(input_ids=ids_tensor)\n",
    "        hidden_states = out.hidden_states\n",
    "        last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        sentence_embedding = torch.cat(tuple(last_four_layers), dim=0)\n",
    "        sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "        sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "        return sentence_embedding.cpu().numpy()\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.apply(self.embed_sentence)\n",
    "        X = pd.DataFrame(X.values.tolist())\n",
    "        return X\n",
    "\n",
    "prep_pipeline = Pipeline([\n",
    "    (\"select_features\", SelectFeatures(features_list=[\"Zweck\"])),\n",
    "    (\"clean_text\", CleanText()),\n",
    "    (\"spacy_lemmatizer\", SpacyLemmatizer()),\n",
    "    (\"text_lowercase\", Lowercase()),\n",
    "    (\"tfidf_vectorizer\", TfIdfVectorizer()),\n",
    "    # (\"bert_sentence_embeddings\", BertSentenceEmbeddigs()),\n",
    "])\n",
    "\n",
    "# Example\n",
    "prep_pipeline.fit_transform(X, y).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters hypertuning and model selection with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "\n",
    "def custom_scorer_macro_f1(y_true,y_pred):\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return macro_f1\n",
    "\n",
    "scorer_macro_f1 = make_scorer(custom_scorer_macro_f1, greater_is_better=True)\n",
    "\n",
    "def custom_scorer_weighted_f1(y_true,y_pred):\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return weighted_f1\n",
    "\n",
    "scorer_weighted_f1 = make_scorer(custom_scorer_weighted_f1, greater_is_better=True)\n",
    "\n",
    "\n",
    "def execute_pipeline(features,labels, search_space=[\n",
    "                    {\"estimator\": [RandomForestClassifier(random_state=42, verbose=1)],\n",
    "                    \"estimator__n_estimators\": [100],\n",
    "                    # \"estimator__max_depth\": [2, 6]\n",
    "                    }], \n",
    "                    cv = 10,\n",
    "                    verbose = 1,\n",
    "                    n_jobs = os.cpu_count() - 2,\n",
    "                    scoring = scorer_macro_f1):\n",
    "                    # scoring = {\"macro_f1\": scorer_macro_f1,\"weighted_f1\": scorer_weighted_f1}):\n",
    "    \n",
    "    pipe = Pipeline([(\"preprocessing\", prep_pipeline),\n",
    "                    (\"estimator\", RandomForestClassifier())])\n",
    "    \n",
    "    gridsearch = GridSearchCV(pipe, search_space, scoring=scoring, cv=cv, verbose=verbose,n_jobs=n_jobs,refit=True)\n",
    "    best_model = gridsearch.fit(features, labels)\n",
    "    print(best_model.best_params_)\n",
    "    print(best_model.best_score_)\n",
    "    return best_model\n",
    "\n",
    "best_estimator = execute_pipeline(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(best_estimator,open(\"pretrained_models/random_forest/best_estimator.pkl\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffdfb0697f174c80f5cf0b5f22ddc30cefc12684f1f3af5faba8742076bf488"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
