{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference:\n",
    "- https://huggingface.co/docs/transformers/training\n",
    "- https://huggingface.co/dbmdz/bert-base-german-cased\n",
    "- https://huggingface.co/bert-base-german-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Base BERT (no preprocessing of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n",
      "EPOCH 1/12\n",
      "\n",
      "\n",
      "Avg training loss:    2.5934352493948407\n",
      "EPOCH 2/12\n",
      "\n",
      "\n",
      "Avg training loss:    2.101401318278578\n",
      "EPOCH 3/12\n",
      "\n",
      "\n",
      "Avg training loss:    1.8058103372653325\n",
      "EPOCH 4/12\n",
      "\n",
      "\n",
      "Avg training loss:    1.491440539351768\n",
      "EPOCH 5/12\n",
      "\n",
      "\n",
      "Avg training loss:    1.2814586069434881\n",
      "EPOCH 6/12\n",
      "\n",
      "\n",
      "Avg training loss:    1.0629782736715343\n",
      "EPOCH 7/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.8888123526444865\n",
      "EPOCH 8/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.7744647389174335\n",
      "EPOCH 9/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.6937694469363325\n",
      "EPOCH 10/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.6170416643015213\n",
      "EPOCH 11/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.564439774180452\n",
      "EPOCH 12/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.5379270181422018\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from lib.bert_pytorch.train import train_model_on_full_train_data, train_model_on_train_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "MODEL_NAME = \"bert-base-german-cased\"\n",
    "# MODEL_NAME = \"bert-base-german-dbmdz-cased\"\n",
    "DATA_PATH = \"data/selected_data.csv\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 12\n",
    "SEED = 42\n",
    "TRAIN_MODEL_ON_FULL_TRAINING_DATA = True\n",
    "SAVE_NEW_MODEL = True\n",
    "DOWNLOAD_WEIGHTS = False\n",
    "\n",
    "\n",
    "if TRAIN_MODEL_ON_FULL_TRAINING_DATA:\n",
    "    model, training_stats = train_model_on_full_train_data(DATA_PATH, MODEL_NAME, BATCH_SIZE, NUM_EPOCHS, SEED)\n",
    "else:\n",
    "    model, training_stats = train_model_on_train_data(DATA_PATH, MODEL_NAME, BATCH_SIZE, NUM_EPOCHS, SEED)\n",
    "# print(\"\\nTraining results: \", training_stats)\n",
    "\n",
    "if SAVE_NEW_MODEL:\n",
    "    torch.save(model.state_dict(), \"pretrained_models/bert_pytorch/model_state_dict.pt\")\n",
    "    torch.save(model, \"pretrained_models/bert_pytorch/entire_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>dataset</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT base baseline</td>\n",
       "      <td>default, 12 epochs</td>\n",
       "      <td>raw without duplicates</td>\n",
       "      <td>0.402406</td>\n",
       "      <td>0.714564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name          parameters                 dataset  macro_f1  \\\n",
       "0  BERT base baseline  default, 12 epochs  raw without duplicates  0.402406   \n",
       "\n",
       "  weighted_f1  \n",
       "0    0.714564  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tmp = pd.read_csv(\"results/results.csv\")\n",
    "tmp = tmp.append(   {\n",
    "                    \"model_name\": \"BERT base baseline\",\n",
    "                    \"parameters\": \"default, 12 epochs\",\n",
    "                    \"dataset\": \"raw without duplicates\",\n",
    "                    \"macro_f1\": training_stats[-1][\"validation_macro_f1_score\"][\"f1\"],\n",
    "                    \"weighted_f1\": training_stats[-1][\"validation_weighted_f1_score\"][\"f1\"]\n",
    "                    },\n",
    "                    ignore_index=True)\n",
    "\n",
    "tmp.to_csv(\"results/results.csv\", index=False)\n",
    "tmp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check system hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Graphics Card Driver:  Wed Feb  2 03:59:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.76       Driver Version: 496.76       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   51C    P8     6W /  N/A |    911MiB /  8192MiB |     25%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                    \n",
      "CUDA version:  nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:35_Pacific_Daylight_Time_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.relgpu_drvr445TC445_37.28845127_0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.bert_pytorch.helper_functions import get_cuda_info, get_torch_info\n",
    "\n",
    "get_cuda_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.7.1+cu110\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: c:\\users\\lisandro\\desktop\\projects\\case-lisandro\\venv\\lib\\site-packages\n",
      "Requires: typing-extensions, numpy\n",
      "Required-by: torchvision, torchaudio \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_torch_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "from lib.bert_pytorch.helper_functions import get_device\n",
    "\n",
    "device = get_device()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffdfb0697f174c80f5cf0b5f22ddc30cefc12684f1f3af5faba8742076bf488"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
