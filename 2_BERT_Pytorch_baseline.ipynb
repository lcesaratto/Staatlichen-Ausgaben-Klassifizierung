{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference:\n",
    "- https://huggingface.co/docs/transformers/training\n",
    "- https://huggingface.co/dbmdz/bert-base-german-cased\n",
    "- https://huggingface.co/bert-base-german-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Base BERT (no preprocessing of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-dbmdz-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-dbmdz-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n",
      "EPOCH 1/3\n",
      "\n",
      "\n",
      "Avg training loss:    2.3148418329656124\n",
      "Avg validation loss:  2.004741996526718\n",
      "F1 validation score:  {'f1': 0.3179720158377108}\n",
      "\n",
      "EPOCH 2/3\n",
      "\n",
      "\n",
      "Avg training loss:    1.8841770105063915\n",
      "Avg validation loss:  1.7829311192035675\n",
      "F1 validation score:  {'f1': 0.4261239415278983}\n",
      "\n",
      "EPOCH 3/3\n",
      "\n",
      "\n",
      "Avg training loss:    1.6716537177562714\n",
      "Avg validation loss:  1.7095335721969604\n",
      "F1 validation score:  {'f1': 0.42675838328893384}\n",
      "\n",
      "\n",
      "Training results:  [{'epoch': 1, 'training_loss': 2.3148418329656124, 'validation_loss': 2.004741996526718, 'validation_f1_score': {'f1': 0.3179720158377108}}, {'epoch': 2, 'training_loss': 1.8841770105063915, 'validation_loss': 1.7829311192035675, 'validation_f1_score': {'f1': 0.4261239415278983}}, {'epoch': 3, 'training_loss': 1.6716537177562714, 'validation_loss': 1.7095335721969604, 'validation_f1_score': {'f1': 0.42675838328893384}}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from lib.bert_pytorch.train import train_model_on_full_train_data, train_model_on_train_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# MODEL_NAME = \"bert-base-german-cased\"\n",
    "MODEL_NAME = \"bert-base-german-dbmdz-cased\"\n",
    "DATA_PATH = \"data/preprocessed_data.csv\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "SEED = 42\n",
    "TRAIN_MODEL_ON_FULL_TRAINING_DATA = False\n",
    "SAVE_NEW_MODEL = True\n",
    "USE_PRETRAINED_MODEL = False\n",
    "DOWNLOAD_WEIGHTS = False\n",
    "\n",
    "if USE_PRETRAINED_MODEL:\n",
    "    if DOWNLOAD_WEIGHTS:\n",
    "        import gdown\n",
    "        print(\"Downloading weights\")\n",
    "        id = \"\"\n",
    "        output = \"pretrained_model/model_state_dict.pt\"\n",
    "        gdown.download(output=output, quiet=False, id=id)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels = 24,\n",
    "            output_attentions = False,\n",
    "            output_hidden_states = False,\n",
    "        )\n",
    "    model.load_state_dict(torch.load(\"pretrained_model/model_state_dict.pt\"))\n",
    "\n",
    "else:\n",
    "    if TRAIN_MODEL_ON_FULL_TRAINING_DATA:\n",
    "        model, training_stats = train_model_on_full_train_data(DATA_PATH, MODEL_NAME, BATCH_SIZE, NUM_EPOCHS, SEED)\n",
    "    else:\n",
    "        model, training_stats = train_model_on_train_data(DATA_PATH, MODEL_NAME, BATCH_SIZE, NUM_EPOCHS, SEED)\n",
    "    print(\"\\nTraining results: \", training_stats)\n",
    "\n",
    "    if SAVE_NEW_MODEL:\n",
    "        torch.save(model.state_dict(), \"pretrained_models/bert_pytorch/model_state_dict.pt\")\n",
    "        torch.save(model, \"pretrained_models/bert_pytorch/entire_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check system hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Graphics Card Driver:  Wed Feb  2 03:59:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.76       Driver Version: 496.76       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   51C    P8     6W /  N/A |    911MiB /  8192MiB |     25%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                    \n",
      "CUDA version:  nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:35_Pacific_Daylight_Time_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.relgpu_drvr445TC445_37.28845127_0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.bert_pytorch.helper_functions import get_cuda_info, get_torch_info\n",
    "\n",
    "get_cuda_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.7.1+cu110\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: c:\\users\\lisandro\\desktop\\projects\\case-lisandro\\venv\\lib\\site-packages\n",
      "Requires: typing-extensions, numpy\n",
      "Required-by: torchvision, torchaudio \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_torch_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "from lib.bert_pytorch.helper_functions import get_device\n",
    "\n",
    "device = get_device()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffdfb0697f174c80f5cf0b5f22ddc30cefc12684f1f3af5faba8742076bf488"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
