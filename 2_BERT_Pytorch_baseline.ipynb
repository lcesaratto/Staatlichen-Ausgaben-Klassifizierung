{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference:\n",
    "- https://huggingface.co/docs/transformers/training\n",
    "- https://huggingface.co/dbmdz/bert-base-german-cased\n",
    "- https://huggingface.co/bert-base-german-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Base BERT (no preprocessing of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n",
      "EPOCH 1/12\n",
      "\n",
      "\n",
      "Avg training loss:    2.3798411823809147\n",
      "Avg validation loss:  1.8919464945793152\n",
      "Macro F1 validation score:  {'f1': 0.07342995169082125}\n",
      "Weighted F1 validation score:  {'f1': 0.374246505066051}\n",
      "\n",
      "EPOCH 2/12\n",
      "\n",
      "\n",
      "Avg training loss:    1.6354505121707916\n",
      "Avg validation loss:  1.5229992866516113\n",
      "Macro F1 validation score:  {'f1': 0.12109885620915034}\n",
      "Weighted F1 validation score:  {'f1': 0.4868910506680548}\n",
      "\n",
      "EPOCH 3/12\n",
      "\n",
      "\n",
      "Avg training loss:    1.2009363789111376\n",
      "Avg validation loss:  1.3190207183361053\n",
      "Macro F1 validation score:  {'f1': 0.2414867677668748}\n",
      "Weighted F1 validation score:  {'f1': 0.5822656235609271}\n",
      "\n",
      "EPOCH 4/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.9282438503578305\n",
      "Avg validation loss:  1.2590060234069824\n",
      "Macro F1 validation score:  {'f1': 0.2523809523809524}\n",
      "Weighted F1 validation score:  {'f1': 0.596881584492204}\n",
      "\n",
      "EPOCH 5/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.7563098296523094\n",
      "Avg validation loss:  1.1937298476696014\n",
      "Macro F1 validation score:  {'f1': 0.2680089111668059}\n",
      "Weighted F1 validation score:  {'f1': 0.622478763279881}\n",
      "\n",
      "EPOCH 6/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.6191905234009027\n",
      "Avg validation loss:  1.209705501794815\n",
      "Macro F1 validation score:  {'f1': 0.31961913330334385}\n",
      "Weighted F1 validation score:  {'f1': 0.6514691539377148}\n",
      "\n",
      "EPOCH 7/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.5210753493010998\n",
      "Avg validation loss:  1.2483678758144379\n",
      "Macro F1 validation score:  {'f1': 0.3142673107890499}\n",
      "Weighted F1 validation score:  {'f1': 0.6514086614509854}\n",
      "\n",
      "EPOCH 8/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.45008696475997567\n",
      "Avg validation loss:  1.1959156692028046\n",
      "Macro F1 validation score:  {'f1': 0.33442039442039445}\n",
      "Weighted F1 validation score:  {'f1': 0.6729941641446067}\n",
      "\n",
      "EPOCH 9/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.3955130144022405\n",
      "Avg validation loss:  1.1685706973075867\n",
      "Macro F1 validation score:  {'f1': 0.386605504587156}\n",
      "Weighted F1 validation score:  {'f1': 0.6957348921544747}\n",
      "\n",
      "EPOCH 10/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.3544202628545463\n",
      "Avg validation loss:  1.1158570647239685\n",
      "Macro F1 validation score:  {'f1': 0.43203145602701654}\n",
      "Weighted F1 validation score:  {'f1': 0.7287457120356651}\n",
      "\n",
      "EPOCH 11/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.31987208407372236\n",
      "Avg validation loss:  1.1204089224338531\n",
      "Macro F1 validation score:  {'f1': 0.40240556828792123}\n",
      "Weighted F1 validation score:  {'f1': 0.7145640235176934}\n",
      "\n",
      "EPOCH 12/12\n",
      "\n",
      "\n",
      "Avg training loss:    0.2883516224101186\n",
      "Avg validation loss:  1.1181460916996002\n",
      "Macro F1 validation score:  {'f1': 0.40240556828792123}\n",
      "Weighted F1 validation score:  {'f1': 0.7145640235176934}\n",
      "\n",
      "\n",
      "Training results:  [{'epoch': 1, 'training_loss': 2.3798411823809147, 'validation_loss': 1.8919464945793152, 'validation_macro_f1_score': {'f1': 0.07342995169082125}, 'validation_weighted_f1_score': {'f1': 0.374246505066051}}, {'epoch': 2, 'training_loss': 1.6354505121707916, 'validation_loss': 1.5229992866516113, 'validation_macro_f1_score': {'f1': 0.12109885620915034}, 'validation_weighted_f1_score': {'f1': 0.4868910506680548}}, {'epoch': 3, 'training_loss': 1.2009363789111376, 'validation_loss': 1.3190207183361053, 'validation_macro_f1_score': {'f1': 0.2414867677668748}, 'validation_weighted_f1_score': {'f1': 0.5822656235609271}}, {'epoch': 4, 'training_loss': 0.9282438503578305, 'validation_loss': 1.2590060234069824, 'validation_macro_f1_score': {'f1': 0.2523809523809524}, 'validation_weighted_f1_score': {'f1': 0.596881584492204}}, {'epoch': 5, 'training_loss': 0.7563098296523094, 'validation_loss': 1.1937298476696014, 'validation_macro_f1_score': {'f1': 0.2680089111668059}, 'validation_weighted_f1_score': {'f1': 0.622478763279881}}, {'epoch': 6, 'training_loss': 0.6191905234009027, 'validation_loss': 1.209705501794815, 'validation_macro_f1_score': {'f1': 0.31961913330334385}, 'validation_weighted_f1_score': {'f1': 0.6514691539377148}}, {'epoch': 7, 'training_loss': 0.5210753493010998, 'validation_loss': 1.2483678758144379, 'validation_macro_f1_score': {'f1': 0.3142673107890499}, 'validation_weighted_f1_score': {'f1': 0.6514086614509854}}, {'epoch': 8, 'training_loss': 0.45008696475997567, 'validation_loss': 1.1959156692028046, 'validation_macro_f1_score': {'f1': 0.33442039442039445}, 'validation_weighted_f1_score': {'f1': 0.6729941641446067}}, {'epoch': 9, 'training_loss': 0.3955130144022405, 'validation_loss': 1.1685706973075867, 'validation_macro_f1_score': {'f1': 0.386605504587156}, 'validation_weighted_f1_score': {'f1': 0.6957348921544747}}, {'epoch': 10, 'training_loss': 0.3544202628545463, 'validation_loss': 1.1158570647239685, 'validation_macro_f1_score': {'f1': 0.43203145602701654}, 'validation_weighted_f1_score': {'f1': 0.7287457120356651}}, {'epoch': 11, 'training_loss': 0.31987208407372236, 'validation_loss': 1.1204089224338531, 'validation_macro_f1_score': {'f1': 0.40240556828792123}, 'validation_weighted_f1_score': {'f1': 0.7145640235176934}}, {'epoch': 12, 'training_loss': 0.2883516224101186, 'validation_loss': 1.1181460916996002, 'validation_macro_f1_score': {'f1': 0.40240556828792123}, 'validation_weighted_f1_score': {'f1': 0.7145640235176934}}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from lib.bert_pytorch.train import train_model_on_full_train_data, train_model_on_train_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "MODEL_NAME = \"bert-base-german-cased\"\n",
    "# MODEL_NAME = \"bert-base-german-dbmdz-cased\"\n",
    "DATA_PATH = \"data/selected_data.csv\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 12\n",
    "SEED = 42\n",
    "TRAIN_MODEL_ON_FULL_TRAINING_DATA = False\n",
    "SAVE_NEW_MODEL = True\n",
    "USE_PRETRAINED_MODEL = False\n",
    "DOWNLOAD_WEIGHTS = False\n",
    "\n",
    "if USE_PRETRAINED_MODEL:\n",
    "    if DOWNLOAD_WEIGHTS:\n",
    "        import gdown\n",
    "        print(\"Downloading weights\")\n",
    "        id = \"\"\n",
    "        output = \"pretrained_models/bert_pytorch/model_state_dict.pt\"\n",
    "        gdown.download(output=output, quiet=False, id=id)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels = 24,\n",
    "            output_attentions = False,\n",
    "            output_hidden_states = False,\n",
    "        )\n",
    "    model.load_state_dict(torch.load(\"pretrained_models/bert_pytorch/model_state_dict.pt\"))\n",
    "\n",
    "else:\n",
    "    if TRAIN_MODEL_ON_FULL_TRAINING_DATA:\n",
    "        model, training_stats = train_model_on_full_train_data(DATA_PATH, MODEL_NAME, BATCH_SIZE, NUM_EPOCHS, SEED)\n",
    "    else:\n",
    "        model, training_stats = train_model_on_train_data(DATA_PATH, MODEL_NAME, BATCH_SIZE, NUM_EPOCHS, SEED)\n",
    "    print(\"\\nTraining results: \", training_stats)\n",
    "\n",
    "    if SAVE_NEW_MODEL:\n",
    "        torch.save(model.state_dict(), \"pretrained_models/bert_pytorch/model_state_dict.pt\")\n",
    "        torch.save(model, \"pretrained_models/bert_pytorch/entire_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>dataset</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT base baseline</td>\n",
       "      <td>default, 12 epochs</td>\n",
       "      <td>raw without duplicates</td>\n",
       "      <td>0.402406</td>\n",
       "      <td>0.714564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name          parameters                 dataset  macro_f1  \\\n",
       "0  BERT base baseline  default, 12 epochs  raw without duplicates  0.402406   \n",
       "\n",
       "  weighted_f1  \n",
       "0    0.714564  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tmp = pd.read_csv(\"results/results.csv\")\n",
    "tmp = tmp.append(   {\n",
    "                    \"model_name\": \"BERT base baseline\",\n",
    "                    \"parameters\": \"default, 12 epochs\",\n",
    "                    \"dataset\": \"raw without duplicates\",\n",
    "                    \"macro_f1\": training_stats[-1][\"validation_macro_f1_score\"][\"f1\"],\n",
    "                    \"weighted_f1\": training_stats[-1][\"validation_weighted_f1_score\"][\"f1\"]\n",
    "                    },\n",
    "                    ignore_index=True)\n",
    "\n",
    "tmp.to_csv(\"results/results.csv\", index=False)\n",
    "tmp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check system hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Graphics Card Driver:  Wed Feb  2 03:59:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.76       Driver Version: 496.76       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   51C    P8     6W /  N/A |    911MiB /  8192MiB |     25%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                    \n",
      "CUDA version:  nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:35_Pacific_Daylight_Time_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.relgpu_drvr445TC445_37.28845127_0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.bert_pytorch.helper_functions import get_cuda_info, get_torch_info\n",
    "\n",
    "get_cuda_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.7.1+cu110\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: c:\\users\\lisandro\\desktop\\projects\\case-lisandro\\venv\\lib\\site-packages\n",
      "Requires: typing-extensions, numpy\n",
      "Required-by: torchvision, torchaudio \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_torch_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "from lib.bert_pytorch.helper_functions import get_device\n",
    "\n",
    "device = get_device()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffdfb0697f174c80f5cf0b5f22ddc30cefc12684f1f3af5faba8742076bf488"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
