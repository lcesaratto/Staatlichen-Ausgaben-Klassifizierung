{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(\"data/preprocessed_data.csv\")\n",
    "df.fillna('',inplace=True)\n",
    "\n",
    "X, y= df.loc[:, df.columns != 'Politikbereich'], df.loc[:,df.columns == 'Politikbereich']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Politikbereich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Politikbereich\n",
       "0              21\n",
       "1               2\n",
       "2              18\n",
       "3              11\n",
       "4              11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(y[\"Politikbereich\"].unique().tolist())\n",
    "\n",
    "y[\"Politikbereich\"] = y[\"Politikbereich\"].apply(lambda s: le.transform([s])[0])\n",
    "\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Random Forest with TD-IDF vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: the vectorizer shouldnt be fitted on both training and validation data, only training. I will correct this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "1920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aad</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abb</th>\n",
       "      <th>abenteuerspielplatz</th>\n",
       "      <th>abgefahren</th>\n",
       "      <th>ablauforganisatorische</th>\n",
       "      <th>abqueer</th>\n",
       "      <th>absatz</th>\n",
       "      <th>absent</th>\n",
       "      <th>absichtserkennung</th>\n",
       "      <th>...</th>\n",
       "      <th>zylinderbohrungen</th>\n",
       "      <th>ältere</th>\n",
       "      <th>öffentlichkeitsarbeit</th>\n",
       "      <th>öffnung</th>\n",
       "      <th>ögb</th>\n",
       "      <th>öpnv</th>\n",
       "      <th>übertragung</th>\n",
       "      <th>überwindung</th>\n",
       "      <th>übungs</th>\n",
       "      <th>übungsleitern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aad  aaron  abb  abenteuerspielplatz  abgefahren  ablauforganisatorische  \\\n",
       "0  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "1  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "2  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "3  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "4  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "\n",
       "   abqueer  absatz  absent  absichtserkennung  ...  zylinderbohrungen  ältere  \\\n",
       "0      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "1      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "2      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "3      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "4      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "\n",
       "   öffentlichkeitsarbeit  öffnung  ögb  öpnv  übertragung  überwindung  \\\n",
       "0                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "1                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "2                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "3                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "4                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "\n",
       "   übungs  übungsleitern  \n",
       "0     0.0            0.0  \n",
       "1     0.0            0.0  \n",
       "2     0.0            0.0  \n",
       "3     0.0            0.0  \n",
       "4     0.0            0.0  \n",
       "\n",
       "[5 rows x 1920 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_tfidf = X.copy()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_tfidf[\"Zweck\"])\n",
    "\n",
    "tfidf_encodings = vectorizer.transform(X_tfidf[\"Zweck\"])\n",
    "\n",
    "X_tfidf = pd.DataFrame(tfidf_encodings.toarray())\n",
    "X_tfidf.columns = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(len(X_tfidf.iloc[0]))\n",
    "\n",
    "X_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    4.5s remaining:   18.4s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.165005</td>\n",
       "      <td>0.041998</td>\n",
       "      <td>0.182503</td>\n",
       "      <td>0.447842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.055007</td>\n",
       "      <td>0.059996</td>\n",
       "      <td>0.316578</td>\n",
       "      <td>0.496362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.190001</td>\n",
       "      <td>0.023999</td>\n",
       "      <td>0.308986</td>\n",
       "      <td>0.539625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.012001</td>\n",
       "      <td>0.066005</td>\n",
       "      <td>0.403031</td>\n",
       "      <td>0.615975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.955001</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.466115</td>\n",
       "      <td>0.546395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.202001</td>\n",
       "      <td>0.027001</td>\n",
       "      <td>0.607859</td>\n",
       "      <td>0.688350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.141001</td>\n",
       "      <td>0.039002</td>\n",
       "      <td>0.503231</td>\n",
       "      <td>0.599808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.965008</td>\n",
       "      <td>0.064992</td>\n",
       "      <td>0.396887</td>\n",
       "      <td>0.499028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.175004</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.481196</td>\n",
       "      <td>0.717489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.188000</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.324742</td>\n",
       "      <td>0.613242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_macro_f1  test_weighted_f1\n",
       "0  3.165005    0.041998       0.182503          0.447842\n",
       "1  3.055007    0.059996       0.316578          0.496362\n",
       "2  3.190001    0.023999       0.308986          0.539625\n",
       "3  3.012001    0.066005       0.403031          0.615975\n",
       "4  2.955001    0.063000       0.466115          0.546395\n",
       "5  3.202001    0.027001       0.607859          0.688350\n",
       "6  3.141001    0.039002       0.503231          0.599808\n",
       "7  2.965008    0.064992       0.396887          0.499028\n",
       "8  3.175004    0.022997       0.481196          0.717489\n",
       "9  3.188000    0.023000       0.324742          0.613242"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "def custom_scorer_macro_f1(y_true,y_pred):\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return macro_f1\n",
    "\n",
    "scorer_macro_f1 = make_scorer(custom_scorer_macro_f1, greater_is_better=True)\n",
    "\n",
    "def custom_scorer_weighted_f1(y_true,y_pred):\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return weighted_f1\n",
    "\n",
    "scorer_weighted_f1 = make_scorer(custom_scorer_weighted_f1, greater_is_better=True)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(rf,\n",
    "                        X_tfidf,\n",
    "                        y[\"Politikbereich\"].values,\n",
    "                        cv=10,\n",
    "                        scoring = {\"macro_f1\": scorer_macro_f1,\"weighted_f1\": scorer_weighted_f1},\n",
    "                        return_train_score = False,\n",
    "                        verbose=1,\n",
    "                        n_jobs=10)\n",
    "                                    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "avg_macro_f1 = scores[\"test_macro_f1\"].mean()\n",
    "avg_weighted_f1 = scores[\"test_weighted_f1\"].mean()\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>dataset</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT base baseline</td>\n",
       "      <td>default, 12 epochs</td>\n",
       "      <td>raw without duplicates</td>\n",
       "      <td>0.402406</td>\n",
       "      <td>0.714564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>default</td>\n",
       "      <td>preprocessed (no augmentation), tfidf</td>\n",
       "      <td>0.399113</td>\n",
       "      <td>0.576411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name          parameters  \\\n",
       "0  BERT base baseline  default, 12 epochs   \n",
       "1       Random Forest             default   \n",
       "\n",
       "                                 dataset  macro_f1  weighted_f1  \n",
       "0                 raw without duplicates  0.402406     0.714564  \n",
       "1  preprocessed (no augmentation), tfidf  0.399113     0.576411  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tmp = pd.read_csv(\"results/results.csv\")\n",
    "tmp = tmp.append(   {\n",
    "                    \"model_name\": \"Random Forest\",\n",
    "                    \"parameters\": \"default\",\n",
    "                    \"dataset\": \"preprocessed (no augmentation), tfidf\",\n",
    "                    \"macro_f1\": avg_macro_f1,\n",
    "                    \"weighted_f1\": avg_weighted_f1\n",
    "                    },\n",
    "                    ignore_index=True)\n",
    "\n",
    "tmp.to_csv(\"results/results.csv\", index=False)\n",
    "tmp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Random Forest with BERT sentence embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/BramVanroy/bert-for-inference/blob/master/introduction-to-bert.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from lib.bert_pytorch.helper_functions import get_device\n",
    "\n",
    "class BERT_sentences_embeddings:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "        self.device = get_device()\n",
    "        self.model = BertModel.from_pretrained('bert-base-german-cased', \n",
    "                                                output_hidden_states=True)\\\n",
    "                                                    .to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def embed_sentence(self, sentence: str):\n",
    "\n",
    "        ids_tensor = self.tokenizer.encode(sentence, return_tensors='pt')\n",
    "\n",
    "        ids_tensor = ids_tensor.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = self.model(input_ids=ids_tensor)\n",
    "\n",
    "        hidden_states = out.hidden_states\n",
    "\n",
    "        # # Last hidden layer\n",
    "        # # print(hidden_states[-1].size()) # torch.Size([1, n_words, 768])\n",
    "        # sentence_embedding = torch.mean(hidden_states[-1], dim=1).squeeze()\n",
    "        # # print(sentence_embedding.size()) # torch.Size([768])\n",
    "\n",
    "        # # Concat last 4 hidden layers (see reference)\n",
    "        # last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        # cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "        # cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "\n",
    "        # Sum last 4 hidden layers\n",
    "        last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        sentence_embedding = torch.cat(tuple(last_four_layers), dim=0)\n",
    "        # print(cat_hidden_states.size()) # torch.Size([4, n_words, 768])\n",
    "        sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "        # print(cat_sentence_embedding.size()) # torch.Size([n_words, 768])\n",
    "        sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "        # print(cat_sentence_embedding.size()) # torch.Size([768])\n",
    "        \n",
    "        return sentence_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321901</td>\n",
       "      <td>-0.172469</td>\n",
       "      <td>0.164475</td>\n",
       "      <td>0.090086</td>\n",
       "      <td>-0.620622</td>\n",
       "      <td>0.396059</td>\n",
       "      <td>-0.243543</td>\n",
       "      <td>0.143387</td>\n",
       "      <td>-0.269414</td>\n",
       "      <td>0.460350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505437</td>\n",
       "      <td>-0.021107</td>\n",
       "      <td>-0.197963</td>\n",
       "      <td>-0.090727</td>\n",
       "      <td>-0.629851</td>\n",
       "      <td>0.024782</td>\n",
       "      <td>-0.517913</td>\n",
       "      <td>0.635020</td>\n",
       "      <td>-0.026206</td>\n",
       "      <td>0.067707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.380983</td>\n",
       "      <td>0.107464</td>\n",
       "      <td>0.550635</td>\n",
       "      <td>0.463361</td>\n",
       "      <td>-0.091500</td>\n",
       "      <td>0.342285</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>-0.160560</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.040033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.889845</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>0.832944</td>\n",
       "      <td>-0.184656</td>\n",
       "      <td>-0.191374</td>\n",
       "      <td>-0.032211</td>\n",
       "      <td>0.089964</td>\n",
       "      <td>-0.028981</td>\n",
       "      <td>-0.436644</td>\n",
       "      <td>0.309008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.014324</td>\n",
       "      <td>-0.254108</td>\n",
       "      <td>0.207883</td>\n",
       "      <td>0.526265</td>\n",
       "      <td>-0.495684</td>\n",
       "      <td>-0.270026</td>\n",
       "      <td>-0.108872</td>\n",
       "      <td>0.266520</td>\n",
       "      <td>-0.361461</td>\n",
       "      <td>0.144416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683479</td>\n",
       "      <td>-0.281656</td>\n",
       "      <td>0.535357</td>\n",
       "      <td>-0.361051</td>\n",
       "      <td>-0.399404</td>\n",
       "      <td>0.091353</td>\n",
       "      <td>-0.240713</td>\n",
       "      <td>0.110006</td>\n",
       "      <td>-0.098588</td>\n",
       "      <td>-0.307411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.691038</td>\n",
       "      <td>0.376838</td>\n",
       "      <td>0.289249</td>\n",
       "      <td>0.238886</td>\n",
       "      <td>-0.051425</td>\n",
       "      <td>-0.265966</td>\n",
       "      <td>-0.228752</td>\n",
       "      <td>0.695132</td>\n",
       "      <td>0.159335</td>\n",
       "      <td>-0.254782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079896</td>\n",
       "      <td>0.448843</td>\n",
       "      <td>0.331829</td>\n",
       "      <td>-0.230279</td>\n",
       "      <td>-0.283521</td>\n",
       "      <td>-0.025756</td>\n",
       "      <td>0.083556</td>\n",
       "      <td>-0.596719</td>\n",
       "      <td>0.272429</td>\n",
       "      <td>0.569072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.281747</td>\n",
       "      <td>0.571193</td>\n",
       "      <td>-0.150270</td>\n",
       "      <td>0.253571</td>\n",
       "      <td>-0.243861</td>\n",
       "      <td>0.186255</td>\n",
       "      <td>0.091825</td>\n",
       "      <td>-0.001978</td>\n",
       "      <td>-0.095922</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.178394</td>\n",
       "      <td>0.231799</td>\n",
       "      <td>-0.655587</td>\n",
       "      <td>-0.779325</td>\n",
       "      <td>-0.244315</td>\n",
       "      <td>0.582203</td>\n",
       "      <td>-0.185745</td>\n",
       "      <td>0.348684</td>\n",
       "      <td>-0.036223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.321901 -0.172469  0.164475  0.090086 -0.620622  0.396059 -0.243543   \n",
       "1 -0.380983  0.107464  0.550635  0.463361 -0.091500  0.342285  0.030745   \n",
       "2 -0.014324 -0.254108  0.207883  0.526265 -0.495684 -0.270026 -0.108872   \n",
       "3  0.691038  0.376838  0.289249  0.238886 -0.051425 -0.265966 -0.228752   \n",
       "4 -0.281747  0.571193 -0.150270  0.253571 -0.243861  0.186255  0.091825   \n",
       "\n",
       "        7         8         9    ...       758       759       760       761  \\\n",
       "0  0.143387 -0.269414  0.460350  ... -0.505437 -0.021107 -0.197963 -0.090727   \n",
       "1 -0.160560  0.061748  0.040033  ... -0.889845  0.006009  0.832944 -0.184656   \n",
       "2  0.266520 -0.361461  0.144416  ... -0.683479 -0.281656  0.535357 -0.361051   \n",
       "3  0.695132  0.159335 -0.254782  ... -0.079896  0.448843  0.331829 -0.230279   \n",
       "4 -0.001978 -0.095922  0.039364  ...  0.043577  0.178394  0.231799 -0.655587   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0 -0.629851  0.024782 -0.517913  0.635020 -0.026206  0.067707  \n",
       "1 -0.191374 -0.032211  0.089964 -0.028981 -0.436644  0.309008  \n",
       "2 -0.399404  0.091353 -0.240713  0.110006 -0.098588 -0.307411  \n",
       "3 -0.283521 -0.025756  0.083556 -0.596719  0.272429  0.569072  \n",
       "4 -0.779325 -0.244315  0.582203 -0.185745  0.348684 -0.036223  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_encoder = BERT_sentences_embeddings()\n",
    "\n",
    "X_bert_sentences_embeddings = X.copy()\n",
    "\n",
    "X_bert_sentences_embeddings = X_bert_sentences_embeddings[\"Zweck\"].apply(lambda s: sentences_encoder.embed_sentence(s))\n",
    "\n",
    "X_bert_sentences_embeddings = pd.DataFrame(X_bert_sentences_embeddings.values.tolist())\n",
    "\n",
    "X_bert_sentences_embeddings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    1.9s remaining:    8.1s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.015987</td>\n",
       "      <td>0.020002</td>\n",
       "      <td>0.145224</td>\n",
       "      <td>0.425327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.016987</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.140488</td>\n",
       "      <td>0.462081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.109027</td>\n",
       "      <td>0.022007</td>\n",
       "      <td>0.168477</td>\n",
       "      <td>0.474726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.008998</td>\n",
       "      <td>0.022002</td>\n",
       "      <td>0.251913</td>\n",
       "      <td>0.496268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.100026</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.251456</td>\n",
       "      <td>0.518174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.043998</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>0.383842</td>\n",
       "      <td>0.579672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.000996</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.273865</td>\n",
       "      <td>0.525934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.010997</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.202736</td>\n",
       "      <td>0.482500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.145999</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.139992</td>\n",
       "      <td>0.429130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.124033</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.451497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_macro_f1  test_weighted_f1\n",
       "0  2.015987    0.020002       0.145224          0.425327\n",
       "1  2.016987    0.022999       0.140488          0.462081\n",
       "2  2.109027    0.022007       0.168477          0.474726\n",
       "3  2.008998    0.022002       0.251913          0.496268\n",
       "4  2.100026    0.023000       0.251456          0.518174\n",
       "5  2.043998    0.018998       0.383842          0.579672\n",
       "6  2.000996    0.020001       0.273865          0.525934\n",
       "7  2.010997    0.024001       0.202736          0.482500\n",
       "8  2.145999    0.022026       0.139992          0.429130\n",
       "9  2.124033    0.013996       0.169600          0.451497"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "def custom_scorer_macro_f1(y_true,y_pred):\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return macro_f1\n",
    "\n",
    "scorer_macro_f1 = make_scorer(custom_scorer_macro_f1, greater_is_better=True)\n",
    "\n",
    "def custom_scorer_weighted_f1(y_true,y_pred):\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return weighted_f1\n",
    "\n",
    "scorer_weighted_f1 = make_scorer(custom_scorer_weighted_f1, greater_is_better=True)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(    rf, \n",
    "                            X_bert_sentences_embeddings, \n",
    "                            y[\"Politikbereich\"].values,\n",
    "                            cv=10,\n",
    "                            scoring = {\"macro_f1\": scorer_macro_f1,\"weighted_f1\": scorer_weighted_f1},\n",
    "                            return_train_score = False,\n",
    "                            verbose=1,\n",
    "                            n_jobs=10\n",
    "                        )\n",
    "                                    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "avg_macro_f1 = scores[\"test_macro_f1\"].mean()\n",
    "avg_weighted_f1 = scores[\"test_weighted_f1\"].mean()\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>dataset</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT base baseline</td>\n",
       "      <td>default, 12 epochs</td>\n",
       "      <td>raw without duplicates</td>\n",
       "      <td>0.402406</td>\n",
       "      <td>0.714564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>default</td>\n",
       "      <td>preprocessed (no augmentation), tfidf</td>\n",
       "      <td>0.399113</td>\n",
       "      <td>0.576411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>default</td>\n",
       "      <td>preprocessed (no augmentation), bert sentence ...</td>\n",
       "      <td>0.212759</td>\n",
       "      <td>0.484531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name          parameters  \\\n",
       "0  BERT base baseline  default, 12 epochs   \n",
       "1       Random Forest             default   \n",
       "2       Random Forest             default   \n",
       "\n",
       "                                             dataset  macro_f1  weighted_f1  \n",
       "0                             raw without duplicates  0.402406     0.714564  \n",
       "1              preprocessed (no augmentation), tfidf  0.399113     0.576411  \n",
       "2  preprocessed (no augmentation), bert sentence ...  0.212759     0.484531  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tmp = pd.read_csv(\"results/results.csv\")\n",
    "tmp = tmp.append(   {\n",
    "                    \"model_name\": \"Random Forest\",\n",
    "                    \"parameters\": \"default\",\n",
    "                    \"dataset\": \"preprocessed (no augmentation), bert sentence embeddings\",\n",
    "                    \"macro_f1\": avg_macro_f1,\n",
    "                    \"weighted_f1\": avg_weighted_f1\n",
    "                    },\n",
    "                    ignore_index=True)\n",
    "\n",
    "tmp.to_csv(\"results/results.csv\", index=False)\n",
    "tmp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters hypertuning and model selection with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "\n",
    "# def custom_scorer(y_true,y_pred):\n",
    "#     macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "#     print(macro_f1)\n",
    "#     weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "#     print(weighted_f1)\n",
    "#     return macro_f1\n",
    "\n",
    "# scorer = make_scorer(custom_scorer, greater_is_better=True)\n",
    "\n",
    "# def execute_pipeline(features,labels, search_space=[\n",
    "#                     {\"estimator\": [RandomForestClassifier(random_state=42, verbose=1, n_jobs=-1)],\n",
    "#                     \"estimator__n_estimators\": [10, 25],\n",
    "#                     \"estimator__max_depth\": [2, 6]\n",
    "#                     }], \n",
    "#                     cv=3,\n",
    "#                     verbose=1,\n",
    "#                     n_jobs=os.cpu_count() - 2,\n",
    "#                     scoring= scorer):\n",
    "    \n",
    "#     pipe = Pipeline([(\"estimator\", RandomForestClassifier())])\n",
    "    \n",
    "#     gridsearch = GridSearchCV(pipe, search_space, scoring=scoring, cv=cv, verbose=verbose,n_jobs=n_jobs)\n",
    "#     best_model = gridsearch.fit(features, labels)\n",
    "#     print(best_model.best_estimator_)\n",
    "#     print(best_model.best_score_)\n",
    "#     return best_model\n",
    "\n",
    "# best_estimator = execute_pipeline(X,y)\n",
    "\n",
    "# pickle.dump(best_estimator,open( \"pretrained_models/random_forest/best_estimator.pkl\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffdfb0697f174c80f5cf0b5f22ddc30cefc12684f1f3af5faba8742076bf488"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
