{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv(\"data/preprocessed_data.csv\")\n",
    "df.fillna('',inplace=True)\n",
    "\n",
    "X, y= df.loc[:, df.columns != 'Politikbereich'], df.loc[:,df.columns == 'Politikbereich']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Politikbereich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Politikbereich\n",
       "0              21\n",
       "1               2\n",
       "2              18\n",
       "3              11\n",
       "4              11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(y[\"Politikbereich\"].unique().tolist())\n",
    "\n",
    "y[\"Politikbereich\"] = y[\"Politikbereich\"].apply(lambda s: le.transform([s])[0])\n",
    "\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD-IDF vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: the vectorizer shouldnt be fitted on both training and validation data, only training. I will correct this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aad</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abb</th>\n",
       "      <th>abenteuerspielplatz</th>\n",
       "      <th>abgefahren</th>\n",
       "      <th>ablauforganisatorische</th>\n",
       "      <th>abqueer</th>\n",
       "      <th>absatz</th>\n",
       "      <th>absent</th>\n",
       "      <th>absichtserkennung</th>\n",
       "      <th>...</th>\n",
       "      <th>zylinderbohrungen</th>\n",
       "      <th>ältere</th>\n",
       "      <th>öffentlichkeitsarbeit</th>\n",
       "      <th>öffnung</th>\n",
       "      <th>ögb</th>\n",
       "      <th>öpnv</th>\n",
       "      <th>übertragung</th>\n",
       "      <th>überwindung</th>\n",
       "      <th>übungs</th>\n",
       "      <th>übungsleitern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aad  aaron  abb  abenteuerspielplatz  abgefahren  ablauforganisatorische  \\\n",
       "0  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "1  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "2  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "3  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "4  0.0    0.0  0.0                  0.0         0.0                     0.0   \n",
       "\n",
       "   abqueer  absatz  absent  absichtserkennung  ...  zylinderbohrungen  ältere  \\\n",
       "0      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "1      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "2      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "3      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "4      0.0     0.0     0.0                0.0  ...                0.0     0.0   \n",
       "\n",
       "   öffentlichkeitsarbeit  öffnung  ögb  öpnv  übertragung  überwindung  \\\n",
       "0                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "1                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "2                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "3                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "4                    0.0      0.0  0.0   0.0          0.0          0.0   \n",
       "\n",
       "   übungs  übungsleitern  \n",
       "0     0.0            0.0  \n",
       "1     0.0            0.0  \n",
       "2     0.0            0.0  \n",
       "3     0.0            0.0  \n",
       "4     0.0            0.0  \n",
       "\n",
       "[5 rows x 1920 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X[\"Zweck\"])\n",
    "\n",
    "tfidf_encodings = vectorizer.transform(X[\"Zweck\"])\n",
    "\n",
    "X = pd.DataFrame(tfidf_encodings.toarray())\n",
    "X.columns = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(vectorizer.vocabulary_))\n",
    "print(len(X.iloc[0]))\n",
    "\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a default RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   3 out of   3 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.67100072, 0.62700319, 0.66500306]),\n",
       " 'score_time': array([0.0459981 , 0.04399872, 0.04099965]),\n",
       " 'test_macro_f1': array([0.19360245, 0.31623307, 0.31377238]),\n",
       " 'test_weighted_f1': array([0.41980581, 0.49310218, 0.54892923])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "def custom_scorer_macro_f1(y_true,y_pred):\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return macro_f1\n",
    "\n",
    "scorer_macro_f1 = make_scorer(custom_scorer_macro_f1, greater_is_better=True)\n",
    "\n",
    "def custom_scorer_weighted_f1(y_true,y_pred):\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return weighted_f1\n",
    "\n",
    "scorer_weighted_f1 = make_scorer(custom_scorer_weighted_f1, greater_is_better=True)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(rf, X, y[\"Politikbereich\"].values, cv=3,\n",
    "                                    scoring = {\"macro_f1\": scorer_macro_f1,\"weighted_f1\": scorer_weighted_f1},\n",
    "                                    return_train_score = False,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=10)\n",
    "                                    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisandro\\AppData\\Local\\Temp\\ipykernel_23924\\4273368958.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(   {\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>dataset</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT base baseline</td>\n",
       "      <td>default, 12 epochs</td>\n",
       "      <td>raw without duplicates</td>\n",
       "      <td>0.402406</td>\n",
       "      <td>0.714564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>default</td>\n",
       "      <td>preprocessed (no augmentation), tfidf</td>\n",
       "      <td>0.313772</td>\n",
       "      <td>0.548929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name          parameters  \\\n",
       "0  BERT base baseline  default, 12 epochs   \n",
       "1       Random Forest             default   \n",
       "\n",
       "                                 dataset  macro_f1  weighted_f1  \n",
       "0                 raw without duplicates  0.402406     0.714564  \n",
       "1  preprocessed (no augmentation), tfidf  0.313772     0.548929  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tmp = pd.read_csv(\"results/results.csv\")\n",
    "tmp = tmp.append(   {\n",
    "                    \"model_name\": \"Random Forest\",\n",
    "                    \"parameters\": \"default\",\n",
    "                    \"dataset\": \"preprocessed (no augmentation), tfidf\",\n",
    "                    \"macro_f1\": 0.31377238,\n",
    "                    \"weighted_f1\": 0.54892923\n",
    "                    },\n",
    "                    ignore_index=True)\n",
    "\n",
    "tmp.to_csv(\"results/results.csv\", index=False)\n",
    "tmp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence embedding with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/BramVanroy/bert-for-inference/blob/master/introduction-to-bert.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from lib.bert_pytorch.helper_functions import get_device\n",
    "\n",
    "class BERT_sentences_embeddings:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "        self.device = get_device()\n",
    "        self.model = BertModel.from_pretrained('bert-base-german-cased', \n",
    "                                                output_hidden_states=True)\\\n",
    "                                                    .to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def embed_sentence(self, sentence: str):\n",
    "\n",
    "        ids_tensor = self.tokenizer.encode(sentence, return_tensors='pt')\n",
    "\n",
    "        ids_tensor = ids_tensor.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = self.model(input_ids=ids_tensor)\n",
    "\n",
    "        hidden_states = out.hidden_states\n",
    "\n",
    "        # # Last hidden layer\n",
    "        # # print(hidden_states[-1].size()) # torch.Size([1, n_words, 768])\n",
    "        # sentence_embedding = torch.mean(hidden_states[-1], dim=1).squeeze()\n",
    "        # # print(sentence_embedding.size()) # torch.Size([768])\n",
    "\n",
    "        # # Concat last 4 hidden layers (see reference)\n",
    "        # last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        # cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "        # cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "\n",
    "        # Sum last 4 hidden layers\n",
    "        last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        sentence_embedding = torch.cat(tuple(last_four_layers), dim=0)\n",
    "        # print(cat_hidden_states.size()) # torch.Size([4, n_words, 768])\n",
    "        sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "        # print(cat_sentence_embedding.size()) # torch.Size([n_words, 768])\n",
    "        sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "        # print(cat_sentence_embedding.size()) # torch.Size([768])\n",
    "        \n",
    "        return sentence_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters hypertuning and model selection with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "\n",
    "# def custom_scorer(y_true,y_pred):\n",
    "#     macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "#     print(macro_f1)\n",
    "#     weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "#     print(weighted_f1)\n",
    "#     return macro_f1\n",
    "\n",
    "# scorer = make_scorer(custom_scorer, greater_is_better=True)\n",
    "\n",
    "# def execute_pipeline(features,labels, search_space=[\n",
    "#                     {\"estimator\": [RandomForestClassifier(random_state=42, verbose=1, n_jobs=-1)],\n",
    "#                     \"estimator__n_estimators\": [10, 25],\n",
    "#                     \"estimator__max_depth\": [2, 6]\n",
    "#                     }], \n",
    "#                     cv=3,\n",
    "#                     verbose=1,\n",
    "#                     n_jobs=os.cpu_count() - 2,\n",
    "#                     scoring= scorer):\n",
    "    \n",
    "#     pipe = Pipeline([(\"estimator\", RandomForestClassifier())])\n",
    "    \n",
    "#     gridsearch = GridSearchCV(pipe, search_space, scoring=scoring, cv=cv, verbose=verbose,n_jobs=n_jobs)\n",
    "#     best_model = gridsearch.fit(features, labels)\n",
    "#     print(best_model.best_estimator_)\n",
    "#     print(best_model.best_score_)\n",
    "#     return best_model\n",
    "\n",
    "# best_estimator = execute_pipeline(X,y)\n",
    "\n",
    "# pickle.dump(best_estimator,open( \"pretrained_models/random_forest/best_estimator.pkl\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffdfb0697f174c80f5cf0b5f22ddc30cefc12684f1f3af5faba8742076bf488"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
