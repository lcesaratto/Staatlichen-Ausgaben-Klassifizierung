{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/preprocessed_data.csv\")\n",
    "df.fillna('',inplace=True)\n",
    "\n",
    "X_train, y_train = df.loc[:, df.columns != 'Politikbereich'], df['Politikbereich']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(y_train[\"Politikbereich\"].unique().tolist())\n",
    "\n",
    "y_train[\"Politikbereich\"] = y_train[\"Politikbereich\"].apply(lambda s: le.transform([s])[0])\n",
    "\n",
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a classifier with grid search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "\n",
    "def my_custom_loss_func(y_true,y_pred):\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(macro_f1)\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(weighted_f1)\n",
    "    return macro_f1\n",
    "\n",
    "macro_f1 = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "def execute_pipeline(features,labels, search_space=[\n",
    "                    {\"estimator\": [RandomForestClassifier(random_state=42, verbose=1, n_jobs=-1)],\n",
    "                    \"estimator__n_estimators\": [10, 25],\n",
    "                    \"estimator__max_depth\": [2, 6]\n",
    "                    }], \n",
    "                    cv=3,\n",
    "                    verbose=1,\n",
    "                    n_jobs=os.cpu_count() - 2,\n",
    "                    scoring= macro_f1):\n",
    "    \n",
    "    pipe = Pipeline([(\"estimator\", RandomForestClassifier())])\n",
    "    \n",
    "    gridsearch = GridSearchCV(pipe, search_space, scoring=scoring, cv=cv, verbose=verbose,n_jobs=n_jobs)\n",
    "    best_model = gridsearch.fit(features, labels)\n",
    "    print(best_model.best_estimator_)\n",
    "    print(best_model.best_score_)\n",
    "    return best_model\n",
    "\n",
    "best_estimator = execute_pipeline(X_train,y_train)\n",
    "\n",
    "pickle.dump(best_estimator,open( \"pretrained_models/random_forest/best_estimator.pkl\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffdfb0697f174c80f5cf0b5f22ddc30cefc12684f1f3af5faba8742076bf488"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
