{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_PIPELINE_AND_MODEL = False\n",
    "\n",
    "if DOWNLOAD_PIPELINE_AND_MODEL:\n",
    "    import gdown\n",
    "    print(\"Downloading preprocessing pipeline\")\n",
    "    id = \"1J0NiJA61QBaj80EswXuqDtEPzF6yM0uW\"\n",
    "    output = \"pretrained_models/random_forest/prep_pipeline.pkl\"\n",
    "    gdown.download(output=output, quiet=False, id=id)\n",
    "    print(\"Downloading model\")\n",
    "    id = \"18JbYn29dK5E4AO_dMsqY0lIkz3yPHC-X\"\n",
    "    output = \"pretrained_models/random_forest/best_estimator.pkl\"\n",
    "    gdown.download(output=output, quiet=False, id=id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from lib.bert_pytorch.helper_functions import get_device\n",
    "\n",
    "class SelectFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_list):\n",
    "        self.features_list = features_list\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X[self.features_list]\n",
    "        X = X.iloc[:,0]\n",
    "        return X\n",
    "\n",
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def cleaner(self, text):\n",
    "        # Remove mid slash and digits\n",
    "        text = re.sub(r'-', ' ', text)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        # Custom ones not supported by spacy\n",
    "        text = re.sub(r'Abs\\.', 'Absatz', text)\n",
    "        text = re.sub(r'e\\.V\\.', 'eingetragener Verein', text)\n",
    "        text = re.sub(r'co\\.', 'Kompanie', text)\n",
    "        text = re.sub(r'Co\\.', 'Kompanie', text)\n",
    "        text = re.sub(r'gem\\.', 'gemäß', text)\n",
    "        text = re.sub(r\"'s\", '', text)\n",
    "        return text\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.apply(self.cleaner)\n",
    "        return X\n",
    "\n",
    "class SpacyLemmatizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"de_core_news_lg\")\n",
    "        self.nlp.remove_pipe(\"ner\")\n",
    "        self.nlp.remove_pipe(\"parser\")\n",
    "        self.nlp.remove_pipe(\"attribute_ruler\")\n",
    "    def normalize(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        output = []\n",
    "        for token in doc:\n",
    "            if not token.is_punct and not token.is_stop and not token.is_space:\n",
    "                output.append(token.lemma_)\n",
    "        return \" \".join(output)\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.apply(self.normalize)\n",
    "        return X\n",
    "\n",
    "class Lowercase(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.apply(lambda text: text.lower())\n",
    "        return X\n",
    "\n",
    "class TfIdfVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        tfidf_encodings = self.vectorizer.transform(X)\n",
    "        X = pd.DataFrame(tfidf_encodings.toarray())\n",
    "        return X\n",
    "\n",
    "class BertSentenceEmbeddigs(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
    "        self.device = get_device()\n",
    "        self.model = BertModel.from_pretrained('bert-base-german-cased', \n",
    "                                                output_hidden_states=True)\\\n",
    "                                                    .to(self.device)\n",
    "        self.model.eval()\n",
    "    def embed_sentence(self, sentence: str):\n",
    "        ids_tensor = self.tokenizer.encode(sentence, return_tensors='pt')\n",
    "        ids_tensor = ids_tensor.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            out = self.model(input_ids=ids_tensor)\n",
    "        hidden_states = out.hidden_states\n",
    "        last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        sentence_embedding = torch.cat(tuple(last_four_layers), dim=0)\n",
    "        sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "        sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "        return sentence_embedding.cpu().numpy()\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.apply(self.embed_sentence)\n",
    "        X = pd.DataFrame(X.values.tolist())\n",
    "        return X\n",
    "\n",
    "prep_pipeline = Pipeline([\n",
    "    (\"select_features\", SelectFeatures(features_list=[\"Zweck\"])),\n",
    "    (\"clean_text\", CleanText()),\n",
    "    (\"spacy_lemmatizer\", SpacyLemmatizer()),\n",
    "    (\"text_lowercase\", Lowercase()),\n",
    "    (\"tfidf_vectorizer\", TfIdfVectorizer()),\n",
    "    # (\"bert_sentence_embeddings\", BertSentenceEmbeddigs()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Add test_data.csv into the /data folder\n",
    "X = pd.read_csv('data/test_data.csv')\n",
    "\n",
    "\n",
    "X.fillna('',inplace=True)\n",
    "\n",
    "prep_pipeline = pickle.load(open(\"pretrained_models/random_forest/prep_pipeline.pkl\", \"rb\" ))\n",
    "\n",
    "X = prep_pipeline.transform(X)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "def custom_scorer_macro_f1(y_true,y_pred):\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return macro_f1\n",
    "\n",
    "scorer_macro_f1 = make_scorer(custom_scorer_macro_f1, greater_is_better=True)\n",
    "\n",
    "best_estimator = pickle.load(open(\"pretrained_models/random_forest/best_estimator.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['prediction'] = best_estimator.predict(X)\n",
    "X.head(5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ffdfb0697f174c80f5cf0b5f22ddc30cefc12684f1f3af5faba8742076bf488"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
